{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import stanza\n",
    "import time\n",
    "from IPython.display import display, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv('D:\\\\DATA603\\\\project\\\\new_MongoDB\\\\review\\\\review_corrected_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stanza.download('en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 19:07:51 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0654ca46e04384baf9fdd400684514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 19:07:52 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-06-26 19:07:52 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| sentiment | sstplus  |\n",
      "========================\n",
      "\n",
      "2023-06-26 19:07:52 WARNING: GPU requested, but is not available!\n",
      "2023-06-26 19:07:52 INFO: Using device: cpu\n",
      "2023-06-26 19:07:52 INFO: Loading: tokenize\n",
      "2023-06-26 19:07:52 INFO: Loading: pos\n",
      "2023-06-26 19:07:52 INFO: Loading: sentiment\n",
      "2023-06-26 19:07:53 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(processors='tokenize,mwt,pos,sentiment', lang='en', use_gpu=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the sentiment of each noun from a sentence\n",
    "number_of_records = len(review_df)\n",
    "\n",
    "def get_noun_sentiment(review, record_count):\n",
    "    noun_sentiment_map = {}\n",
    "    flat_sentiment = ''\n",
    "    start_time_cpu = time.time()\n",
    "    for sentence in nlp(review).sentences:\n",
    "        sentiment = sentence.sentiment\n",
    "        for word in sentence.words:\n",
    "            if word.pos.startswith('N'):\n",
    "                noun_sentiment_map[word.text] = sentiment\n",
    "    record_count[0] += 1\n",
    "    end_time_cpu = time.time()\n",
    "    # logging.info(f'Processed {record_count[0]} out of {record_count[1]}.')\n",
    "    # print(f'Processed {record_count[0]} out of {record_count[1]}.')\n",
    "    # print(f'Time: {end_time_cpu - start_time_cpu}.')\n",
    "    clear_output(wait=True)  # Clears the output cell before displaying the next message\n",
    "    display(f'Processed {record_count[0]} out of {record_count[1]}.')\n",
    "    return noun_sentiment_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sentiment extraction from the reviews is taking a very long time. \n",
    "2. spelling checker took 6 hours to run.\n",
    "3. so i need to batch it.\n",
    "   \n",
    "   1. Write the corrected_text table to a csv file.\n",
    "   2. Run sentiment extraction by batching the data by business_id.\n",
    "   3. After completing every run, write the file with appropriate filename to the disk.\n",
    "   4. use what ever file is ready, and let it run in the background for however long it needs.\n",
    "   5. Full sentiment extraction should be done in a little more than 73 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business ids \n",
    "business_ids = review_df.groupby('business_id')['stars'].count().sort_values().index.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 25 out of 28401. Time: 7.920673608779907.\n",
      "Processed 26 out of 28401. Time: 10.565166473388672.\n"
     ]
    }
   ],
   "source": [
    "review_df.loc[:, 'review_sentiment'] = review_df[review_df['business_id'] == \"Rt4xYQBWC8i2xqLp9dP7XQ\"]['corrected_text'][:2].apply(lambda x: get_noun_sentiment(x, record_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_file_to_disk(df, filename):\n",
    "    df.to_csv(filename, index=False,)\n",
    "\n",
    "# File map\n",
    "business_file_map = {}\n",
    "def batch_sentiment_extraction(b_id, business_number, business_file_map):\n",
    "    batch_size = len(review_df[review_df['business_id'] == b_id])\n",
    "    record_count = [0, batch_size]\n",
    "    print(f'Sentiment Extraction of {b_id} Beginning.')\n",
    "    print(f'Batch size: {batch_size}.')\n",
    "    review_df.loc[:, 'review_sentiment'] = review_df[review_df['business_id'] == b_id]['corrected_text'].apply(lambda x: get_noun_sentiment(x, record_count))\n",
    "    print(f'Sentiment Extraction of {b_id} Complete.')\n",
    "    print('Writing the file to disk...')\n",
    "    processed_sentiment = review_df.loc[review_df['business_id'] == b_id]\n",
    "    write_file_to_disk(processed_sentiment, f'sentiment/b_num_{business_number}.csv')\n",
    "    business_file_map[business_number] = f'{b_id}'\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_file_map = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def begin_batch_processing(business_ids, business_file_map):\n",
    "\n",
    "    for idx, b_id in enumerate(business_ids):\n",
    "        if b_id in business_file_map.values():\n",
    "            continue\n",
    "        else:\n",
    "            batch_sentiment_extraction(b_id, idx, business_file_map)\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write few processed records at a time to the file.\n",
    "2. Keep track of which indexes are done. \n",
    "3. Resume on restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Processed 3427 out of 3427.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Extraction of IkY2ticzHEn4QFn8hQLSWg Complete.\n",
      "Writing the file to disk...\n"
     ]
    }
   ],
   "source": [
    "begin_batch_processing(business_ids, business_file_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_ids_df = pd.DataFrame(data=business_file_map.values(), index=business_file_map.keys(), columns=['business_id'])\n",
    "business_ids_df.to_csv(\"business_ids_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Rt4xYQBWC8i2xqLp9dP7XQ',\n",
       " 1: 'k37i1EW_x848o_n1ATcErg',\n",
       " 2: '5t-25pkm9ovVcbH3BBIpCw',\n",
       " 3: 'P5Wq5OwEJ0Zz7piLoToXDA',\n",
       " 4: 'YkXedtqYoQGXgNFHLClYIQ',\n",
       " 5: 'C809UuprygJyEgJw4wr2Pg',\n",
       " 6: 'Ri2S4YEre3xTmWUCO2XEGQ',\n",
       " 7: 'UNWb37aMC3nuWdszceGMxg',\n",
       " 8: 'roKcuykq_7CNMcTGtNUmYg',\n",
       " 9: 'RGzIHIhOIZzsjLRVDvSjRQ',\n",
       " 10: 'UwI-vRH7Mu6PmsPR67MXyw',\n",
       " 11: '-tRhEoFo5viTTPX316ut6w',\n",
       " 12: 'UoDicg0wO3Q1JPUymA-91w',\n",
       " 13: 'Rv6P37KiiuowrXti2JHZNQ',\n",
       " 14: 'tNOLXgYTykXmLaAZnvo1vg',\n",
       " 15: 'XX0xyWDpFc6Diq-XVHUckg',\n",
       " 16: 'AlnAoqsqChTn1Eg3dzLmMw',\n",
       " 17: '38yHZCHWgPZlDj5SqdNcpA',\n",
       " 18: 'VVarKkODJTs_qx_gz4Hxbg',\n",
       " 19: '6rRGA1V-mLl7f2BqqZ_AmA',\n",
       " 20: '8ynnZAfsIHltv72hiM-rlA',\n",
       " 21: 'zJoT9gFvGtZAhbdcIF4Xmw',\n",
       " 22: 'QUshQjkKA_s0yTrxOGbRrQ',\n",
       " 23: 'UMHuKs1sO-wq3XqKaejXeA',\n",
       " 24: 'pXVGayL-fCoAMci3G1dRzA',\n",
       " 25: 'jF3RPKNsdcb4657pNRbGxQ',\n",
       " 26: '8bUZSK2GPfwkGRbh06r07w',\n",
       " 27: 'UhjfJpaAzgSYrTZ_dMMF1Q',\n",
       " 28: 'PmFBiD-KW4U_L1MS9qcIUQ',\n",
       " 29: 'YRw8RmnSc1olsEFTf5H6Eg',\n",
       " 30: 'uf4gH2bLBox8bCHw30kJxQ',\n",
       " 31: 'yxQs5gSf0-8cEd6YMgSjbw',\n",
       " 32: 'rF0xI_3jjlsEKp3N0Z0BuQ',\n",
       " 33: 'dISs1oH_xeNAOOEcmJiGZQ',\n",
       " 34: 'lkQP24RF-W7Hvb2WOPJWAw',\n",
       " 35: 'OOv7OvZlExF2Z3Q569RtEw',\n",
       " 36: '9D0aKRGsutg8S0ClIanmrA',\n",
       " 37: 'or4XkblYRyXHxKJuKbhx_Q',\n",
       " 38: 'hNBHvMSy3SQeVHfGI4vHKQ',\n",
       " 39: 'leXPdmhrrc9Uov1B-zn-WA',\n",
       " 40: '8LHwxmeaY1Ovh4_ekqXXJg',\n",
       " 41: 'VeN-0RlU_UqxXQR7cmz0QA',\n",
       " 42: 'BIfo9AKEpC8oIwB60YAR_A',\n",
       " 43: 'WRMlifrYLjRY8q5YUUbfZA',\n",
       " 44: 'gw68ejeDgZZ2kCAHvFroNQ',\n",
       " 45: 'kT8IlV47kz1rz2lTuNyO1w',\n",
       " 46: 'WoFttPbJRti49sXBgOeIBQ',\n",
       " 47: 'ZForVw2ZTiwDGfZ0XvZsXQ',\n",
       " 48: 'aVslIwCbkM8zEKcJ_c9qIg',\n",
       " 49: 'o2sdqQ7e4IzeBWxUo_-tFQ',\n",
       " 50: '_1Ep7fi7vCY3J2rz6YGQmw',\n",
       " 51: 'y6-J_UjNk69VNLb39c_5CA',\n",
       " 52: 'kBLMIhzYGoqKm2EK4GME8A',\n",
       " 53: 'GTNh2Jx56qE5kJSOVZxZlg',\n",
       " 54: '93K-xlLwLnwcFuV2r2MI6Q',\n",
       " 55: 'zYu2D8FzczailDkEMURExg',\n",
       " 56: 'Y-phVflbb6RjFCDPEH_DoA',\n",
       " 57: 'Bq69zDUTbBrfmtB9OBH9uA',\n",
       " 58: 'VTJaTUZ91_OEASP9RFMK0A',\n",
       " 59: 'GROg6x3Lf-Tp3TgiTtYsoA',\n",
       " 60: 'QGzyGNkNBnB1q6KgeUL3Cg',\n",
       " 61: 'GSiZfdrbw72LF1D2xTaTzQ',\n",
       " 62: '6_Gsn1ZxSosWb6mZusap0Q',\n",
       " 63: '7Flr6AcqSBotjFPB0gFhYA',\n",
       " 64: 'zBT8l6b3wE_H541Msvg4Wg',\n",
       " 65: '69ccjOpx2iFvr1y2qas9uA',\n",
       " 66: 'mNXfzN6L3GPJdUJXbSsmfw',\n",
       " 67: 'TE2IEDNV0RcI6s1wTOP4fg',\n",
       " 68: 'S5LnH1njwFBlq77tIkjI1g',\n",
       " 69: 'wMQkdK2aNMvq2xoojC98Mw',\n",
       " 70: 'bjQrmBSu1A7f5vprEikOKA',\n",
       " 71: 'E5FcXykvHP9geCmhxv8szA',\n",
       " 72: 'qHe8EQyf72nWO633eGxG7A',\n",
       " 73: 's3ZR7G5l-YN5fqms8vRSRw',\n",
       " 74: '8va8lpVU8aiQtnSbyjVScA',\n",
       " 75: '1N9WC6FwF8MSc7BHbIP35A',\n",
       " 76: 'nYeTVhBwwF5aCGYo9-aLGw',\n",
       " 77: 'IAgeKx3Z3_JqMjcAOCy2dQ',\n",
       " 78: 'rQ5xsCMH6Xdk4NnmdeA3Eg',\n",
       " 79: 'EVmCBFlY0Hy_62bDRizmGA',\n",
       " 80: 'zBzWWSk4sW0W1mhNjyzN1w',\n",
       " 81: 'wtVJXrChHTjcaisSpzGCVw',\n",
       " 82: 'Cjwb7VQGP0u2eWYj1wnO3g',\n",
       " 83: 'n5P6-HWN3kFSYBxfVfDxEg',\n",
       " 84: '-FasKNAqishyfjAarVgJtw',\n",
       " 85: 'oJxsRgj8Un9VAPXpaDuufA',\n",
       " 86: 'vWRdL8B9o2CmUmfJgNgMqQ',\n",
       " 87: 'U158K3VPSN8ZFlJ1rlR4FA',\n",
       " 88: 'tjU_hYVEFsUFJzVNqoMFiQ',\n",
       " 89: '_A2YtPqLxss0uLhRey5yCw',\n",
       " 90: 'e3Y3hDpwHc9RmQlJtIgHuw',\n",
       " 91: 'D9p7-HsY9llYP3BaCVg4DA',\n",
       " 92: 'vl40Oa75v42jvJsHwpCGKA',\n",
       " 93: 'H1Azz4BpHYC8BlUAdMlfxw',\n",
       " 94: 'LImOqXSWUq-E_eNZhTUzmQ',\n",
       " 95: 'tOPDno-cu5NQO56FeOBg-g',\n",
       " 96: 'CnhmThuteYExAEvBSzL0qg',\n",
       " 97: 'ZfOS7Mz-iGseNxBhlhXm_w',\n",
       " 98: 'qY-BUQY-SFBaSrFHowF3nA',\n",
       " 99: 'p_qSQwShIgQnNxGcajI4-w',\n",
       " 100: 'IkY2ticzHEn4QFn8hQLSWg'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_file_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rt4xYQBWC8i2xqLp9dP7XQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k37i1EW_x848o_n1ATcErg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5t-25pkm9ovVcbH3BBIpCw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P5Wq5OwEJ0Zz7piLoToXDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YkXedtqYoQGXgNFHLClYIQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>tOPDno-cu5NQO56FeOBg-g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>CnhmThuteYExAEvBSzL0qg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ZfOS7Mz-iGseNxBhlhXm_w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>qY-BUQY-SFBaSrFHowF3nA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>p_qSQwShIgQnNxGcajI4-w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id\n",
       "0   Rt4xYQBWC8i2xqLp9dP7XQ\n",
       "1   k37i1EW_x848o_n1ATcErg\n",
       "2   5t-25pkm9ovVcbH3BBIpCw\n",
       "3   P5Wq5OwEJ0Zz7piLoToXDA\n",
       "4   YkXedtqYoQGXgNFHLClYIQ\n",
       "..                     ...\n",
       "95  tOPDno-cu5NQO56FeOBg-g\n",
       "96  CnhmThuteYExAEvBSzL0qg\n",
       "97  ZfOS7Mz-iGseNxBhlhXm_w\n",
       "98  qY-BUQY-SFBaSrFHowF3nA\n",
       "99  p_qSQwShIgQnNxGcajI4-w\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_ids_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
